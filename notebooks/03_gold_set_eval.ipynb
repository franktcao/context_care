{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13124162",
   "metadata": {},
   "source": [
    "# Gold Set Evaluation\n",
    "\n",
    "Evaluating an LLM's accuracy is not straightforward. Traditional classification\n",
    "metrics like accuracy, precision, recall, and f_beta are well suited for when \n",
    "there are discrete classes so that Type I and Type II errors can be measured.\n",
    "However when there are many different answers, all with semantic similarity, \n",
    "a more robust and understanding evaluation is required.\n",
    "\n",
    "*Note:* Of course, you can make your LLM answer yes/no or even multiple choice \n",
    "questions but the LLM is capable of so much more that won't be assessed.\n",
    "\n",
    "For these reasons, to capture semantic similarity between generated answers from\n",
    "the LLM and expected answers, we go back to the embedding space. Here, the \n",
    "context and semantic meaning is captured in training, so we can use the vector \n",
    "store to embed the generated and expected answers as vectors and measure the \n",
    "cosine-similarity in the embedding space. Similarities of these vectors \n",
    "correspond to similarities between answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab718ec",
   "metadata": {},
   "source": [
    "## Load\n",
    "Let's start by loading in the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OLLAMA_SERVER_URL = os.getenv(\"OLLAMA_SERVER_URL\")\n",
    "DPATH_VECTORSTORE = Path.cwd() / \"data\" / \"vectorstore\"\n",
    "\n",
    "client = ollama.Client(host=OLLAMA_SERVER_URL)\n",
    "models_server = client.list()[\"models\"]\n",
    "model_names = [model.model for model in models_server]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the only model in the server\n",
    "model_name = model_names[0]\n",
    "\n",
    "EMBEDDINGS = OllamaEmbeddings(model=model_name, base_url=OLLAMA_SERVER_URL)\n",
    "vector_store_path = DPATH_VECTORSTORE / \"vs_deepseek-r1\"\n",
    "VECTOR_STORE = FAISS.load_local(\n",
    "    vector_store_path, embeddings=EMBEDDINGS, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86032bf",
   "metadata": {},
   "source": [
    "# Load in Gold Set Session\n",
    "\n",
    "Load in a session that was intended to ask questions where we have an expected \n",
    "answer. That way we can compare the answer we expect with the answer the LLM\n",
    "generated. \n",
    "\n",
    "Here, there should be many more questions, provided with subject matter experts\n",
    "who know the answers and can evaluate responses to provide feedback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "307305f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "chatbot_output",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "response_time_sec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "reference_page",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "context_pdf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_pages",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_feedback",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9e5ecc9d-0756-4303-98c5-52839464a705",
       "rows": [
        [
         "3",
         "2945694660",
         "why is the sky blue?",
         "<think>\nOkay, let's start by understanding the user's query. They provided a study context about HER-2/neu gene amplification in breast cancer and then asked \"Why is the sky blue?\" That seems odd at first glance because these two topics are unrelated.\n\nFirst, I need to check if there's any connection between the study mentioned and the question about the sky color. The references talk about oncogenes, receptors, statistical tests like chi-square, and other scientific aspects related to breast cancer research. There's no mention of atmospheric science or light scattering in this context. So, the answer should be straightforward—there's no link.\n\nNow, considering the user might be a Novice familiar with the study. They probably read the provided text but didn't notice the unrelated question. Maybe they're testing if I can distinguish between relevant and irrelevant questions based on the given context. Or perhaps there was a typo or misdirection in their query.\n\nThe sky blue phenomenon is explained by Rayleigh scattering, where shorter wavelengths of light (blue) scatter more than longer ones (red). The study's focus isn't on this, so responding with \"I don't know\" makes sense unless the user intended to ask something else related to the study. But given the context provided, there's no connection.\n\nThe user might be confused or trying to see if I can handle tangential questions. Alternatively, they could have made a mistake in copying the question. Their deeper need is likely accurate information on their actual query, which here seems misplaced. They probably want an answer about the study but phrased it incorrectly by including the sky blue question.\n\nI should respond clearly that there's no relation between the two topics and explain why I can't answer based on the provided context. This approach addresses both the surface question and the possible underlying need for clarification.\n</think>\nI don't know",
         "11.44895",
         "7",
         "SlamonetalSCIENCE1987.pdf",
         "8",
         null,
         "2025-06-10 00:30:16.946532",
         null
        ],
        [
         "4",
         "2945694660",
         "what is HER-2/neu",
         "<think>\nHmm, the user wants me to explain what HER-2/neu is for someone with a Novice level of familiarity. They've provided some scientific text from a study about breast cancer and gene amplification.\n\nLooking at this context, I can see that it's discussing a research study on breast cancers where they evaluated DNA changes in the HER-2/neu gene across 103 tumors. The text mentions using radioactive probes to detect amplification of this gene - specifically showing that 18% of samples had evidence of HER-2/neu gene amplification.\n\nThe user is asking about HER-2/neu, which appears to be a key focus in their study. From the context, I can see it's being studied as part of breast cancer research at the University of Texas San Antonio. The text explains they used Southern blot analysis with radioactive probes to detect this gene amplification.\n\nI should explain that HER-2/neu is a specific type of receptor protein found on some breast cells and other tissues. It's important because when it's amplified (meaning there are multiple copies in cancer cells), it can drive tumor growth more aggressively than normal. This makes HER-2 status particularly relevant for determining appropriate treatment options.\n\nI'll keep my explanation simple but informative, focusing on what the gene does normally, how amplification changes its behavior, and why this matters clinically - especially since they're asking about something related to breast cancer research.\n</think>\nOkay, let's break down that question based on the provided study context:\n\n**What is HER-2/neu?**\n\nIn simple terms, **HER-2/neu refers to a specific type of receptor protein found on some cells.**\n\nHere's what it means in this study context:\n1.  It's located on the surface of certain breast cells (and other tissues like stomach).\n2.  The HER-2 gene provides instructions for making this receptor.\n3.  In normal, healthy cells, this receptor helps control cell growth and division.\n4.  However, in some aggressive forms of **breast cancer**, the *HER-2* gene is often found to be **amplified** (meaning there are many copies of it). This leads to too much production of the HER-2 protein on the surface of tumor cells.\n\nThe study specifically looked for this amplification using DNA tests and radioactive probes. Finding that a breast cancer has amplified *HER-2* genes is important because:\n*   It indicates a more aggressive type of breast cancer.\n*   This information helps doctors decide if certain targeted treatments (like Herceptin) might be effective.\n\nSo, the study was examining how many copies of this specific gene were present in tumor samples and linking that to their potential aggressiveness.",
         "18.639963",
         "6",
         "SlamonetalSCIENCE1987.pdf",
         "8",
         null,
         "2025-06-10 00:40:51.758936",
         null
        ],
        [
         "5",
         "2945694660",
         "In the initial survey, tissue from how many breast cancers was evaluated for alterations in the HER-2/neu gene?",
         "<think>\nOkay, let's tackle this query step by step. The user is asking about the number of breast cancer tissues evaluated in the initial survey for HER-2/neu gene alterations.\n\nFirst, I need to locate the relevant information in the provided study context. Scanning through the text, there are mentions of \"cases\" and sample sizes. Specifically, looking at the part where they discuss HER-2/neu amplification versus EGFR, it says \"all filters were analyzed with the HER-2/ neu probe (Fig. 3).\" Then in the next paragraph, they mention analyzing all filters for EGFR as well.\n\nThe key sentence here is: \"Amplification of the HER-2/neu gene was found in 53/189 cases.\" The number 189 appears right after stating that amplification was found in 53 out of these cases. So, the total number of breast cancer tissues evaluated would be 189.\n\nI should also consider if there's any other part of the study mentioning a different sample size for HER-2/neu alone. The text says they used \"the x² test\" on various disease parameters and combined groups (5 to 20 cases and over 20). But when specifically asking about HER-2/neu, it refers back to the same 189 samples mentioned in the EGFR analysis.\n\nTherefore, confirming that all filters analyzed for EGFR were also used for HER-2/neu. The initial survey here is part of a larger study with 189 cases. So the answer should be 189.\n</think>\nIn the initial survey described in the text, tissue from **189** breast cancers was evaluated for alterations in the HER-2/neu gene (as indicated by amplification and rearrangement).",
         "14.046112",
         "6",
         "SlamonetalSCIENCE1987.pdf",
         "8",
         null,
         "2025-06-10 00:47:28.563297",
         null
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_input</th>\n",
       "      <th>chatbot_output</th>\n",
       "      <th>response_time_sec</th>\n",
       "      <th>reference_page</th>\n",
       "      <th>context_pdf</th>\n",
       "      <th>pdf_pages</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>why is the sky blue?</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's start by understanding th...</td>\n",
       "      <td>11.448950</td>\n",
       "      <td>7</td>\n",
       "      <td>SlamonetalSCIENCE1987.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-10 00:30:16.946532</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>what is HER-2/neu</td>\n",
       "      <td>&lt;think&gt;\\nHmm, the user wants me to explain wha...</td>\n",
       "      <td>18.639963</td>\n",
       "      <td>6</td>\n",
       "      <td>SlamonetalSCIENCE1987.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-10 00:40:51.758936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>In the initial survey, tissue from how many br...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's tackle this query step by...</td>\n",
       "      <td>14.046112</td>\n",
       "      <td>6</td>\n",
       "      <td>SlamonetalSCIENCE1987.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-10 00:47:28.563297</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                         user_input  \\\n",
       "3  2945694660                               why is the sky blue?   \n",
       "4  2945694660                                  what is HER-2/neu   \n",
       "5  2945694660  In the initial survey, tissue from how many br...   \n",
       "\n",
       "                                      chatbot_output  response_time_sec  \\\n",
       "3  <think>\\nOkay, let's start by understanding th...          11.448950   \n",
       "4  <think>\\nHmm, the user wants me to explain wha...          18.639963   \n",
       "5  <think>\\nOkay, let's tackle this query step by...          14.046112   \n",
       "\n",
       "   reference_page                context_pdf  pdf_pages  user_feedback  \\\n",
       "3               7  SlamonetalSCIENCE1987.pdf          8            NaN   \n",
       "4               6  SlamonetalSCIENCE1987.pdf          8            NaN   \n",
       "5               6  SlamonetalSCIENCE1987.pdf          8            NaN   \n",
       "\n",
       "                   created_at  updated_at  \n",
       "3  2025-06-10 00:30:16.946532         NaN  \n",
       "4  2025-06-10 00:40:51.758936         NaN  \n",
       "5  2025-06-10 00:47:28.563297         NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dpath = Path.cwd() / \"data\" / \"sessions\"\n",
    "fname = \"chat_history_session_2945694660.csv\"\n",
    "fpath = dpath / fname\n",
    "\n",
    "raw = pd.read_csv(fpath, index_col = 0)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ee3da",
   "metadata": {},
   "source": [
    "Here, an irrelevant question is asked to make sure the model doesn't make up an\n",
    "answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11500d",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "Let's look at the relevant columns and add answers that are expected with an answer key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10cd6c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "chatbot_output",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_answer",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e4055acb-9f7b-4c82-b101-1d564718f2ac",
       "rows": [
        [
         "3",
         "2945694660",
         "why is the sky blue?",
         "<think>\nOkay, let's start by understanding the user's query. They provided a study context about HER-2/neu gene amplification in breast cancer and then asked \"Why is the sky blue?\" That seems odd at first glance because these two topics are unrelated.\n\nFirst, I need to check if there's any connection between the study mentioned and the question about the sky color. The references talk about oncogenes, receptors, statistical tests like chi-square, and other scientific aspects related to breast cancer research. There's no mention of atmospheric science or light scattering in this context. So, the answer should be straightforward—there's no link.\n\nNow, considering the user might be a Novice familiar with the study. They probably read the provided text but didn't notice the unrelated question. Maybe they're testing if I can distinguish between relevant and irrelevant questions based on the given context. Or perhaps there was a typo or misdirection in their query.\n\nThe sky blue phenomenon is explained by Rayleigh scattering, where shorter wavelengths of light (blue) scatter more than longer ones (red). The study's focus isn't on this, so responding with \"I don't know\" makes sense unless the user intended to ask something else related to the study. But given the context provided, there's no connection.\n\nThe user might be confused or trying to see if I can handle tangential questions. Alternatively, they could have made a mistake in copying the question. Their deeper need is likely accurate information on their actual query, which here seems misplaced. They probably want an answer about the study but phrased it incorrectly by including the sky blue question.\n\nI should respond clearly that there's no relation between the two topics and explain why I can't answer based on the provided context. This approach addresses both the surface question and the possible underlying need for clarification.\n</think>\nI don't know",
         "I don't know"
        ],
        [
         "4",
         "2945694660",
         "what is HER-2/neu",
         "<think>\nHmm, the user wants me to explain what HER-2/neu is for someone with a Novice level of familiarity. They've provided some scientific text from a study about breast cancer and gene amplification.\n\nLooking at this context, I can see that it's discussing a research study on breast cancers where they evaluated DNA changes in the HER-2/neu gene across 103 tumors. The text mentions using radioactive probes to detect amplification of this gene - specifically showing that 18% of samples had evidence of HER-2/neu gene amplification.\n\nThe user is asking about HER-2/neu, which appears to be a key focus in their study. From the context, I can see it's being studied as part of breast cancer research at the University of Texas San Antonio. The text explains they used Southern blot analysis with radioactive probes to detect this gene amplification.\n\nI should explain that HER-2/neu is a specific type of receptor protein found on some breast cells and other tissues. It's important because when it's amplified (meaning there are multiple copies in cancer cells), it can drive tumor growth more aggressively than normal. This makes HER-2 status particularly relevant for determining appropriate treatment options.\n\nI'll keep my explanation simple but informative, focusing on what the gene does normally, how amplification changes its behavior, and why this matters clinically - especially since they're asking about something related to breast cancer research.\n</think>\nOkay, let's break down that question based on the provided study context:\n\n**What is HER-2/neu?**\n\nIn simple terms, **HER-2/neu refers to a specific type of receptor protein found on some cells.**\n\nHere's what it means in this study context:\n1.  It's located on the surface of certain breast cells (and other tissues like stomach).\n2.  The HER-2 gene provides instructions for making this receptor.\n3.  In normal, healthy cells, this receptor helps control cell growth and division.\n4.  However, in some aggressive forms of **breast cancer**, the *HER-2* gene is often found to be **amplified** (meaning there are many copies of it). This leads to too much production of the HER-2 protein on the surface of tumor cells.\n\nThe study specifically looked for this amplification using DNA tests and radioactive probes. Finding that a breast cancer has amplified *HER-2* genes is important because:\n*   It indicates a more aggressive type of breast cancer.\n*   This information helps doctors decide if certain targeted treatments (like Herceptin) might be effective.\n\nSo, the study was examining how many copies of this specific gene were present in tumor samples and linking that to their potential aggressiveness.",
         "HER-2/neu is a receptor protein that, in healthy cells, helps control cell growth and division."
        ],
        [
         "5",
         "2945694660",
         "In the initial survey, tissue from how many breast cancers was evaluated for alterations in the HER-2/neu gene?",
         "<think>\nOkay, let's tackle this query step by step. The user is asking about the number of breast cancer tissues evaluated in the initial survey for HER-2/neu gene alterations.\n\nFirst, I need to locate the relevant information in the provided study context. Scanning through the text, there are mentions of \"cases\" and sample sizes. Specifically, looking at the part where they discuss HER-2/neu amplification versus EGFR, it says \"all filters were analyzed with the HER-2/ neu probe (Fig. 3).\" Then in the next paragraph, they mention analyzing all filters for EGFR as well.\n\nThe key sentence here is: \"Amplification of the HER-2/neu gene was found in 53/189 cases.\" The number 189 appears right after stating that amplification was found in 53 out of these cases. So, the total number of breast cancer tissues evaluated would be 189.\n\nI should also consider if there's any other part of the study mentioning a different sample size for HER-2/neu alone. The text says they used \"the x² test\" on various disease parameters and combined groups (5 to 20 cases and over 20). But when specifically asking about HER-2/neu, it refers back to the same 189 samples mentioned in the EGFR analysis.\n\nTherefore, confirming that all filters analyzed for EGFR were also used for HER-2/neu. The initial survey here is part of a larger study with 189 cases. So the answer should be 189.\n</think>\nIn the initial survey described in the text, tissue from **189** breast cancers was evaluated for alterations in the HER-2/neu gene (as indicated by amplification and rearrangement).",
         "103"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_input</th>\n",
       "      <th>chatbot_output</th>\n",
       "      <th>expected_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>why is the sky blue?</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's start by understanding th...</td>\n",
       "      <td>I don't know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>what is HER-2/neu</td>\n",
       "      <td>&lt;think&gt;\\nHmm, the user wants me to explain wha...</td>\n",
       "      <td>HER-2/neu is a receptor protein that, in healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>In the initial survey, tissue from how many br...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's tackle this query step by...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                         user_input  \\\n",
       "3  2945694660                               why is the sky blue?   \n",
       "4  2945694660                                  what is HER-2/neu   \n",
       "5  2945694660  In the initial survey, tissue from how many br...   \n",
       "\n",
       "                                      chatbot_output  \\\n",
       "3  <think>\\nOkay, let's start by understanding th...   \n",
       "4  <think>\\nHmm, the user wants me to explain wha...   \n",
       "5  <think>\\nOkay, let's tackle this query step by...   \n",
       "\n",
       "                                     expected_answer  \n",
       "3                                       I don't know  \n",
       "4  HER-2/neu is a receptor protein that, in healt...  \n",
       "5                                                103  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answers from article and web search lookup\n",
    "answer_key = {\n",
    "    \"why is the sky blue?\": \"I don't know\",\n",
    "    \"what is HER-2/neu\": \"HER-2/neu is a receptor protein that, in healthy cells, helps control cell growth and division.\",\n",
    "    \"In the initial survey, tissue from how many breast cancers was evaluated for alterations in the HER-2/neu gene?\": \"103\",\n",
    "}\n",
    "\n",
    "prepared = (\n",
    "    raw\n",
    "    .filter([\"session_id\", \"user_input\", \"chatbot_output\"])\n",
    "    .assign(expected_answer=lambda x: x[\"user_input\"].map(answer_key))\n",
    ")\n",
    "prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913ca21",
   "metadata": {},
   "source": [
    "## Embed Answers\n",
    "Let's embed answers so that we can compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe705e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "chatbot_output",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generated_embeded",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "expected_embeded",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "05eb3be6-896f-49aa-a378-e8718489dca7",
       "rows": [
        [
         "3",
         "2945694660",
         "why is the sky blue?",
         "<think>\nOkay, let's start by understanding the user's query. They provided a study context about HER-2/neu gene amplification in breast cancer and then asked \"Why is the sky blue?\" That seems odd at first glance because these two topics are unrelated.\n\nFirst, I need to check if there's any connection between the study mentioned and the question about the sky color. The references talk about oncogenes, receptors, statistical tests like chi-square, and other scientific aspects related to breast cancer research. There's no mention of atmospheric science or light scattering in this context. So, the answer should be straightforward—there's no link.\n\nNow, considering the user might be a Novice familiar with the study. They probably read the provided text but didn't notice the unrelated question. Maybe they're testing if I can distinguish between relevant and irrelevant questions based on the given context. Or perhaps there was a typo or misdirection in their query.\n\nThe sky blue phenomenon is explained by Rayleigh scattering, where shorter wavelengths of light (blue) scatter more than longer ones (red). The study's focus isn't on this, so responding with \"I don't know\" makes sense unless the user intended to ask something else related to the study. But given the context provided, there's no connection.\n\nThe user might be confused or trying to see if I can handle tangential questions. Alternatively, they could have made a mistake in copying the question. Their deeper need is likely accurate information on their actual query, which here seems misplaced. They probably want an answer about the study but phrased it incorrectly by including the sky blue question.\n\nI should respond clearly that there's no relation between the two topics and explain why I can't answer based on the provided context. This approach addresses both the surface question and the possible underlying need for clarification.\n</think>\nI don't know",
         "I don't know",
         "[ 0.00134929  0.00494975  0.00188955 ... -0.00146104 -0.00370189\n -0.00722843]",
         "[ 0.00016478 -0.001797   -0.0024264  ...  0.00063223 -0.00157005\n -0.0026961 ]"
        ],
        [
         "4",
         "2945694660",
         "what is HER-2/neu",
         "<think>\nHmm, the user wants me to explain what HER-2/neu is for someone with a Novice level of familiarity. They've provided some scientific text from a study about breast cancer and gene amplification.\n\nLooking at this context, I can see that it's discussing a research study on breast cancers where they evaluated DNA changes in the HER-2/neu gene across 103 tumors. The text mentions using radioactive probes to detect amplification of this gene - specifically showing that 18% of samples had evidence of HER-2/neu gene amplification.\n\nThe user is asking about HER-2/neu, which appears to be a key focus in their study. From the context, I can see it's being studied as part of breast cancer research at the University of Texas San Antonio. The text explains they used Southern blot analysis with radioactive probes to detect this gene amplification.\n\nI should explain that HER-2/neu is a specific type of receptor protein found on some breast cells and other tissues. It's important because when it's amplified (meaning there are multiple copies in cancer cells), it can drive tumor growth more aggressively than normal. This makes HER-2 status particularly relevant for determining appropriate treatment options.\n\nI'll keep my explanation simple but informative, focusing on what the gene does normally, how amplification changes its behavior, and why this matters clinically - especially since they're asking about something related to breast cancer research.\n</think>\nOkay, let's break down that question based on the provided study context:\n\n**What is HER-2/neu?**\n\nIn simple terms, **HER-2/neu refers to a specific type of receptor protein found on some cells.**\n\nHere's what it means in this study context:\n1.  It's located on the surface of certain breast cells (and other tissues like stomach).\n2.  The HER-2 gene provides instructions for making this receptor.\n3.  In normal, healthy cells, this receptor helps control cell growth and division.\n4.  However, in some aggressive forms of **breast cancer**, the *HER-2* gene is often found to be **amplified** (meaning there are many copies of it). This leads to too much production of the HER-2 protein on the surface of tumor cells.\n\nThe study specifically looked for this amplification using DNA tests and radioactive probes. Finding that a breast cancer has amplified *HER-2* genes is important because:\n*   It indicates a more aggressive type of breast cancer.\n*   This information helps doctors decide if certain targeted treatments (like Herceptin) might be effective.\n\nSo, the study was examining how many copies of this specific gene were present in tumor samples and linking that to their potential aggressiveness.",
         "HER-2/neu is a receptor protein that, in healthy cells, helps control cell growth and division.",
         "[ 0.00714642 -0.00315499 -0.00891964 ...  0.00505741  0.01966205\n  0.01437496]",
         "[ 0.01164396  0.00083907  0.00592895 ... -0.00101011  0.00087885\n  0.00171105]"
        ],
        [
         "5",
         "2945694660",
         "In the initial survey, tissue from how many breast cancers was evaluated for alterations in the HER-2/neu gene?",
         "<think>\nOkay, let's tackle this query step by step. The user is asking about the number of breast cancer tissues evaluated in the initial survey for HER-2/neu gene alterations.\n\nFirst, I need to locate the relevant information in the provided study context. Scanning through the text, there are mentions of \"cases\" and sample sizes. Specifically, looking at the part where they discuss HER-2/neu amplification versus EGFR, it says \"all filters were analyzed with the HER-2/ neu probe (Fig. 3).\" Then in the next paragraph, they mention analyzing all filters for EGFR as well.\n\nThe key sentence here is: \"Amplification of the HER-2/neu gene was found in 53/189 cases.\" The number 189 appears right after stating that amplification was found in 53 out of these cases. So, the total number of breast cancer tissues evaluated would be 189.\n\nI should also consider if there's any other part of the study mentioning a different sample size for HER-2/neu alone. The text says they used \"the x² test\" on various disease parameters and combined groups (5 to 20 cases and over 20). But when specifically asking about HER-2/neu, it refers back to the same 189 samples mentioned in the EGFR analysis.\n\nTherefore, confirming that all filters analyzed for EGFR were also used for HER-2/neu. The initial survey here is part of a larger study with 189 cases. So the answer should be 189.\n</think>\nIn the initial survey described in the text, tissue from **189** breast cancers was evaluated for alterations in the HER-2/neu gene (as indicated by amplification and rearrangement).",
         "103",
         "[0.00310503 0.016526   0.00205999 ... 0.00567655 0.01322456 0.00114561]",
         "[ 0.00028179  0.00218079  0.00036941 ... -0.00377231 -0.00034733\n -0.00520641]"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_input</th>\n",
       "      <th>chatbot_output</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>generated_embeded</th>\n",
       "      <th>expected_embeded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>why is the sky blue?</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's start by understanding th...</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>[0.0013492916, 0.004949752, 0.0018895468, 0.00...</td>\n",
       "      <td>[0.00016478242, -0.0017969977, -0.0024264022, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>what is HER-2/neu</td>\n",
       "      <td>&lt;think&gt;\\nHmm, the user wants me to explain wha...</td>\n",
       "      <td>HER-2/neu is a receptor protein that, in healt...</td>\n",
       "      <td>[0.007146416, -0.0031549868, -0.008919642, -5....</td>\n",
       "      <td>[0.0116439555, 0.000839068, 0.005928954, 0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2945694660</td>\n",
       "      <td>In the initial survey, tissue from how many br...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's tackle this query step by...</td>\n",
       "      <td>103</td>\n",
       "      <td>[0.0031050346, 0.016526, 0.0020599884, -0.0129...</td>\n",
       "      <td>[0.0002817883, 0.0021807922, 0.00036940924, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                         user_input  \\\n",
       "3  2945694660                               why is the sky blue?   \n",
       "4  2945694660                                  what is HER-2/neu   \n",
       "5  2945694660  In the initial survey, tissue from how many br...   \n",
       "\n",
       "                                      chatbot_output  \\\n",
       "3  <think>\\nOkay, let's start by understanding th...   \n",
       "4  <think>\\nHmm, the user wants me to explain wha...   \n",
       "5  <think>\\nOkay, let's tackle this query step by...   \n",
       "\n",
       "                                     expected_answer  \\\n",
       "3                                       I don't know   \n",
       "4  HER-2/neu is a receptor protein that, in healt...   \n",
       "5                                                103   \n",
       "\n",
       "                                   generated_embeded  \\\n",
       "3  [0.0013492916, 0.004949752, 0.0018895468, 0.00...   \n",
       "4  [0.007146416, -0.0031549868, -0.008919642, -5....   \n",
       "5  [0.0031050346, 0.016526, 0.0020599884, -0.0129...   \n",
       "\n",
       "                                    expected_embeded  \n",
       "3  [0.00016478242, -0.0017969977, -0.0024264022, ...  \n",
       "4  [0.0116439555, 0.000839068, 0.005928954, 0.006...  \n",
       "5  [0.0002817883, 0.0021807922, 0.00036940924, 0....  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_text(vector_store, text: str) -> np.ndarray:\n",
    "    return np.array(vector_store.embedding_function.embed_query(text))\n",
    "\n",
    "processed = (\n",
    "    prepared\n",
    "    .assign(\n",
    "        generated_embeded=lambda x: x.apply(lambda row: embed_text(VECTOR_STORE, row[\"chatbot_output\"]), axis=\"columns\"),\n",
    "        expected_embeded=lambda x: x.apply(lambda row: embed_text(VECTOR_STORE, row[\"expected_answer\"]), axis=\"columns\"),\n",
    "\n",
    "    )\n",
    ")\n",
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78476a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9282745 , 0.81796825, 0.85264665],\n",
       "       [0.46150412, 0.58925928, 0.40713658],\n",
       "       [0.34591719, 0.47816363, 0.30056028]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch import cosine_similarity\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "\n",
    "similarities = cosine_similarity(\n",
    "    processed[\"generated_embeded\"].tolist(), \n",
    "    processed[\"expected_embeded\"].tolist()\n",
    ")\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc6f91",
   "metadata": {},
   "source": [
    "`similarities` above are pairwise similarities of all generated and expected \n",
    "values so the only ones that make sense to evaluate are the diagonal (first \n",
    "generated vs first expected, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2730d266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9282745 , 0.58925928, 0.30056028])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_similarities = np.diag(similarities)\n",
    "eval_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7372e5b",
   "metadata": {},
   "source": [
    "The similarities to evaluate, `eval_similarities`, measure the relevance of the \n",
    "answers for each question. To evalute the model's performance in aggregate, we \n",
    "can take the average across the gold set to get a sense on how well the model \n",
    "does overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "819d625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060313542407915"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_avg_similiarity = eval_similarities.mean()\n",
    "gs_avg_similiarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
